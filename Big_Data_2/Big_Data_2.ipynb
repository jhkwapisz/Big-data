{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Big Data w biznesie"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drugi notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def _set_css_style(css_file_path):\n",
    "   \"\"\"\n",
    "   Read the custom CSS file and load it into Jupyter.\n",
    "   Pass the file path to the CSS file.\n",
    "   \"\"\"\n",
    "\n",
    "   styles = open(css_file_path, \"r\").read()\n",
    "   s = '<style>%s</style>' % styles\n",
    "   return HTML(s)\n",
    "_set_css_style(\"../custom.css\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwszym krokiem, jak zawsze, jest zaimportowanie potrzebnych nam bibliotek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Zapisywanie i wczytywanie z opcjami"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funkcja `read_csv(\"./lokalizacja_pliku/nazwa_pliku.csv\")` zazwyczaj stara się określić typ danych na podstawie zawartości poszczególnych kolumn. Jednak w niektórych przypadkach może to prowadzić do nieprawidłowych typów danych, szczególnie jeśli dane są niejednoznaczne lub niedostatecznie reprezentatywne.\n",
    "\n",
    "Szczególnie w przypadku danych kategorycznych może być konieczne ręczne określenie typów danych. Po wczytaniu danych warto sprawdzić i ewentualnie poprawić typy danych w DataFrame.\n",
    "\n",
    "Aby zapewnić poprawność typów danych, można skorzystać z innych narzędzi i technik, takich jak ręczne określenie typów danych za pomocą parametru `dtype` lub późniejsza zmiana typu danych kolumn za pomocą metody `astype()`.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na przykład zmiana typu danych w kolumnie `'color'` może wyglądać następująco:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./cars.csv\")\n",
    "df['color'] = df['color'].astype('category')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./cars.csv\", dtype = {'color' :'category'})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jesteśmy też w stanie zmienić nazwę kolumny.\n",
    "\n",
    "Na przykład, jeśli uznamy, że kolumna `'drivetrain'` (rodzaj napędu) powinna nazywać się po prostu `'drive'` możemy to zrobić w następujący sposób:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.rename(columns={'drivetrain':'drive'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Funkcje i obliczenia na wszystkich kolumnach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aby wykonywać działania na kolumnach w pandas, można wykorzystać operatory arytmetyczne (+, -, *, /, ** itp.) lub funkcje z biblioteki numpy (np.sqrt(), np.exp(), np.logical_or itp.). Można również definiować własne funkcje i zastosować je do kolumn za pomocą metody apply().\n",
    "\n",
    "Żeby dodać wartości dwóch kolumn i utworzyć nową kolumnę, można użyć następującego kodu:\n",
    "\n",
    "`df['sum'] = df['column1'] + df['column2']`\n",
    "\n",
    "Na przykład, jeśli chciałbym w nowej kolumnie poznać sumę roku produkcji i odczytu z licznika, wyglądałoby to następująco:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['sum_of_year_and_odometer'] = df['year_produced'] + df['odometer_value']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podobnie, aby pomnożyć wartości kolumny razy dwa, można użyć operatora * lub funkcji np.multiply():\n",
    "\n",
    "- `df['column_2_times'] = df['column'] * 2`\n",
    "\n",
    "\n",
    "- `df['column_2_times'] = np.multiply(df['column'], 2)`\n",
    "\n",
    "\n",
    "- `df['column_2_times'] = df['column'].apply(lambda x: x*2)`\n",
    "\n",
    "Można również stosować bardziej skomplikowane operacje i funkcje do kolumn, w zależności od potrzeb.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na przykład możemy sprawdzić, czy dany samochód jest moim wymarzonym samochodem. Taki samochód musi spełniać trzy warunki:\n",
    "- posiadać czarny kolor,\n",
    "- posiadać automatyczną skrzynię biegów,\n",
    "- mieć pojemność silnika powyżej 3.5 l.\n",
    "\n",
    "Możemy to sprawdzić w następujący sposób:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['is_dream_car'] = np.logical_and(df['color'] == 'black', df['transmission'] == 'automatic', df['engine_capacity'] > 3.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "W ten sposób dostanę nową kolumnę z wartościami `'True'` albo `'False'`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jednak do tego typu zadań, czyli szukania danych spełniających konkretne warunki lepiej nadaje się funkcja `df.query()`.\n",
    "\n",
    "Funkcja `df.query()` służy do filtrowania wierszy w ramach danego DataFrame na podstawie warunków logicznych określonych w łańcuchu znaków. W praktyce funkcja ta działa tak, jakbyśmy przekazali do niej wyrażenie warunkowe, które zwróci wartości `True` dla wierszy, które chcemy wybrać.\n",
    "\n",
    "Przykładowo, jeśli chcemy wybrać wiersze z kolumny `'Age'` w ramach DataFrame, w których wartość jest większa niż 18, możemy użyć funkcji `df.query()` w następujący sposób:\n",
    "\n",
    "\n",
    "`df.query('Age > 18')`\n",
    "\n",
    "Funkcja `df.query()` umożliwia także odwoływanie się do zmiennych, które zostały zdefiniowane wcześniej w skrypcie. Na przykład, jeśli chcemy użyć wartości granicznej jako zmienną, możemy to zrobić w ten sposób:\n",
    "\n",
    "`threshold = 18`\n",
    "`df.query('Age > @threshold')`\n",
    "\n",
    "Funkcja `df.query()` umożliwia również wykorzystanie operatorów logicznych takich jak `and`, `or` i `not` w warunkach, co pozwala na bardziej skomplikowane zapytania.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wracając do moje wymarzonego samochodu, zapytanie o taki samochód może wyglądać następująco:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_capacity = 3.5\n",
    "best_color = 'black'\n",
    "df.query('color == @best_color and transmission == \"automatic\" and engine_capacity > @min_capacity')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jest jeszcze jeden ważny sposób działania bezpośrednio na kolumnach.\n",
    "\n",
    "Metoda `df.str` jest dostępna dla obiektów typu Series i służy do operacji na wartościach typu tekstowego (string) w kolumnie.\n",
    "\n",
    "Niektóre z metod związanych z metodą `df.str` to:\n",
    "\n",
    " - `df.str.contains()`: zwraca wartości True lub False dla każdego wiersza w kolumnie, w zależności od tego, czy dany łańcuch znaków zawiera podany wzorzec.\n",
    " - `df.str.replace()`: zastępuje określony łańcuch znaków innym łańcuchem.\n",
    " - `df.str.split()`: dzieli łańcuch znaków na listę łańcuchów na podstawie określonego separatora.\n",
    " - `df.str.strip()`: usuwa białe znaki z początku i końca każdego łańcucha znaków.\n",
    " - `df.str.upper()`: zamienia wszystkie litery w łańcuchu na wielkie litery.\n",
    " - `df.str.lower()`: zamienia wszystkie litery w łańcuchu na małe litery.\n",
    "\n",
    "Metoda `df.str` może być wykorzystywana do wielu innych operacji na łańcuchach znaków."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kilka przykładów zastosowania.\n",
    "\n",
    "Wyobraźmy sobie, że marka Fiat zmieniła nazwę na Ferrari. W celu zachowania spójności w kolumnie z markami samochodów chcemy zmienić każdy napis 'Fiat' na 'Ferrari'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.query('manufacturer_name == \"Fiat\"')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['manufacturer_name'] = df['manufacturer_name'].str.replace('Fiat', 'Ferrari')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.query('manufacturer_name == \"Ferrari\"')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Możemy też chcieć stworzyć nową kolumnę, w której wszystkie nazwy modelu są zapisane wielkimi literami."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['model_name_upper'] = df['model_name'].str.upper()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['model_name_upper']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To, co łączy te wszystkie metody to, że wykonywane są bezpośrednio na kolumnach i ich wartościach.\n",
    "\n",
    "Przeciwieństwem takiego podejścia jest iterowanie po kolumnach lub indeksach, którego za wszelką cenę powinniśmy unikać z kilku powodów:\n",
    "\n",
    " - Wydajność: iterowanie po każdym elemencie kolumny lub indeksu jest czasochłonne i może spowodować duże obciążenie pamięci, szczególnie dla dużych zbiorów danych. Zamiast tego, w Pandas zaleca się wykorzystywanie wbudowanych metod, które pozwalają na wykonanie operacji na całych kolumnach lub wierszach, co zazwyczaj jest znacznie bardziej wydajne.\n",
    "\n",
    " - Trudność w utrzymaniu: iterowanie po kolumnach lub indeksach może być trudne w utrzymaniu i prowadzić do błędów w kodzie, szczególnie gdy zbiór danych ulega zmianie.\n",
    "\n",
    " - Brak funkcjonalności: iterowanie po kolumnach lub indeksach ogranicza naszą zdolność do korzystania ze wbudowanych funkcjonalności w Pandas, takich jak indeksowanie, filtrowanie, grupowanie, sortowanie i łączenie danych.\n",
    "\n",
    "Zamiast iteracji po kolumnach lub indeksach w Pandas, zaleca się wykorzystywanie wbudowanych metod, takich jak:\n",
    "- `loc`,\n",
    "- `iloc`,\n",
    "- `apply`,\n",
    "- `applymap`,\n",
    "- `map`,\n",
    "- `groupby`,\n",
    "- `merge` i wiele innych.\n",
    "\n",
    "Pozwalają one na wykonanie złożonych operacji na całych kolumnach lub wierszach, co jest znacznie bardziej wydajne i łatwiejsze do utrzymania."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Działania na części danych\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wspominaliśmy pobieżnie o `df.loc`. Funkcja `df.loc` służy do wybierania wierszy i kolumn z DataFrame za pomocą etykiet (nazw) indeksu oraz etykiet nazw kolumn.\n",
    "\n",
    "Funkcja ta przyjmuje dwa argumenty: pierwszy argument określa wybrane wiersze, drugi argument określa wybrane kolumny. Możliwe wartości pierwszego argumentu to:\n",
    "\n",
    " - pojedyncza etykieta indeksu (nazwa wiersza) - zwraca wybrany wiersz\n",
    " - lista etykiet indeksu - zwraca wybrane wiersze\n",
    " - obiekt typu slice (np. slice('2022-01-01', '2022-12-31')) - zwraca wiersze zawierające się w przedziale\n",
    "\n",
    "Możliwe wartości drugiego argumentu to:\n",
    "\n",
    " - pojedyncza etykieta kolumny - zwraca wybraną kolumnę\n",
    " - lista etykiet kolumn - zwraca wybrane kolumny\n",
    " - obiekt typu slice - zwraca kolumny zawierające się w przedziale\n",
    " wyrażenie boolowskie (np. `df['column_name'] > 5`) - zwraca kolumny spełniające określone warunki\n",
    "\n",
    "Przykłady użycia funkcji `df.loc`:\n",
    "\n",
    "\n",
    "   `# zwraca wiersz o indeksie '3'`\n",
    "   `df.loc['3']`\n",
    "\n",
    "   `# zwraca wiersze o indeksach '1' i '2'`\n",
    "   `df.loc[['1', '2']]`\n",
    "\n",
    "   `# zwraca wiersze od '2022-01-01' do '2022-12-31' (włącznie)`\n",
    "   `df.loc['2022-01-01':'2022-12-31']`\n",
    "\n",
    "   `# zwraca kolumnę 'column_name'`\n",
    "   `df.loc[:, 'column_name']`\n",
    "\n",
    "   `# zwraca kolumny 'column_name1' i 'column_name2'`\n",
    "   `df.loc[:, ['column_name1', 'column_name2']]`\n",
    "\n",
    "   `# zwraca kolumny od 'column_name1' do 'column_name3' (włącznie)`\n",
    "   `df.loc[:, 'column_name1':'column_name3']`\n",
    "\n",
    "   `# zwraca wiersze, gdzie wartość w kolumnie 'column_name' jest większa niż 5`\n",
    "   `df.loc[df['column_name'] > 5]`\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Poniżej przedstawię kilka przykładów ciekawych zastosowań tej funkcji, które mogą być bardzo przydatne w różnych przypadkach."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funkcja `df.describe(include = \"all\")` w bibliotece Pandas zwraca statystyki opisowe dla wszystkich kolumn w DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wyobraźmy sobie, że chcemy poznać liczbę unikalnych wartości w każdej kolumnie. Ta informacja jest przechowywana pod indeksem 'unique' i można się do niej odwołać przy użyciu metody `df.loc`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_unique = df.describe(include='all').loc['unique', :]\n",
    "df_unique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jeżeli ilość unikalnych wartości w każdej kolumnie jest niewielka, warto rozważyć zmianę typu danych na `'category'`. Możemy to zrobić za pomocą funkcji `df.loc`, która pozwala na wyświetlanie kolumn lub wierszy spełniających określone warunki boolowskie (`'True'` albo `'False'`). W tym przypadku poszukujemy nazw kolumn, dla których istnieje mniej niż 20 unikalnych wartości."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_unique.loc[df_unique < 20]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funkcja `df.loc` umożliwia odwoływanie się do konkretnych wierszy i/lub kolumn w DataFrame, a jej argumentami są etykiety indeksów i/lub nazwy kolumn."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df_sample = df_copy.sample(n = 10)\n",
    "df_sample.index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Metoda `df.index` zwraca listę etykiet indeksów, które służą do odwoływania się do konkretnych wierszy w DataFrame. Przykładem może być użycie funkcji `df.loc`, w której etykiety indeksów są używane jako pierwszy argument. Powyżej wygenerowaliśmy listę etykiet indeksów tylko dla 10 wylosowanych wierszy, a teraz wykorzystamy ją do zmiany wartości kolumny `'odometer_value'` na 0 dla tych wierszy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_copy.loc[df_sample.index, 'odometer_value'] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " W ten sposób, `df_copy.loc[df_sample.index, 'odometer_value']` odwołuje się tylko do kolumny `'odometer_value'` dla wierszy, których etykiety indeksów znajdują się w `df_sample.index`. Następnie przypisuje wartość 0 dla tych wierszy i tej kolumny, co oznacza, że wartość `'odometer_value'` zostanie wyzerowana tylko dla wylosowanych 10 wierszy, a pozostałe wiersze pozostaną bez zmian.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ostatnie zastosowanie funkcji df.loc może się przydać podczas łączenia kolumn lub DataFrame'ów w Pandas.\n",
    "\n",
    "Polega na połączeniu danych z dwóch lub więcej kolumn/DataFrame'ów w jeden większy DataFrame.\n",
    "\n",
    "Można to zrobić na kilka sposobów, w zależności od potrzeb. Najczęściej wykorzystuje się funkcje:\n",
    "- concat() -  łączy DataFrame'y poprzez dodanie kolejnych kolumn,\n",
    "- merge() - umożliwia łączenie na podstawie klucza,\n",
    "- join() - łączy po indeksie lub kolumnie.\n",
    "\n",
    "Wszystkie te funkcje pozwalają na ustawienie różnych parametrów, takich jak rodzaj łączenia (inner, outer, left, right), typ łączenia (column-wise, row-wise), sposób sortowania danych itp.\n",
    "\n",
    "W wyniku łączenia DataFrame'ów może pojawić się sytuacja, gdzie niektóre kolumny będą zduplikowane. Zdarza się to gdy oba DataFrame'y posiadają kolumny o identycznych nazwach lub w wyniku nieprawidłowego przetwarzania danych.\n",
    "\n",
    "Tutaj połączymy ze sobą dwa identyczne DataFrame'y, co spowoduje powstanie wynikowego DataFrame'a zawierającego wszystkie kolumny zduplikowane."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_copy_1 = df.copy()\n",
    "df_copy_2 = df.copy()\n",
    "df_copy = pd.concat([df_copy_1, df_copy_2], axis=1)\n",
    "print('Liczba kolumn w obiekcie df wynosi: {0}, a w obiekcie df_copy wynosi {1}.'.format(len(df.columns), len(df_copy.columns)))\n",
    "df_copy['manufacturer_name']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Za pomocą funkcji df.loc możemy usunąć zduplikowane kolumny z df_copy.\n",
    "\n",
    "Funkcja df_copy.columns.duplicated() zwraca listę wartości logicznych określających, które kolumny są zduplikowane, a znak tyldy (~) służy do zanegowania tych wartości.\n",
    "\n",
    "Ostatecznie możemy odwołać do wszytskich kolumn, które nie są duplikatem i w ten sposób otrzymamy DataFrame z każdą kolumną występującą tylko raz.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dzięki funkcji `df.loc` możemy usunąć zduplikowane kolumny z DataFrame `df_copy`.\n",
    "\n",
    "Wykorzystujemy funkcję `df_copy.columns.duplicated()`, która zwraca listę wartości logicznych określających, które kolumny są zduplikowane.\n",
    "\n",
    "W celu usunięcia tych kolumn wykorzystujemy operator `~`, aby zanegować te wartości i wybrać tylko kolumny, które nie są zduplikowane.\n",
    "\n",
    "W ten sposób otrzymujemy DataFrame `df_copy` zawierający tylko unikalne kolumny."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_copy = df_copy.loc[:,~df_copy.columns.duplicated()]\n",
    "print('Liczba kolumn w obiekcie df wynosi: {0}, a w obiekcie df_copy wynosi {1}.'.format(len(df.columns), len(df_copy.columns)))\n",
    "df_copy['manufacturer_name']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Grupowanie danych"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grupowanie danych w analizie danych służy do agregacji i przekształcania danych w taki sposób, aby uzyskać wgląd w związki między różnymi zmiennymi lub kategoriami danych. Grupowanie umożliwia analizę danych w sposób bardziej zrozumiały i bardziej przystępny dla użytkowników, którzy mogą szukać wzorców, trendów, relacji lub innych istotnych informacji w danych. Grupowanie jest często stosowane w dziedzinach takich jak biznes, nauka, finanse i wiele innych, gdzie istnieje potrzeba analizy dużych zbiorów danych.\n",
    "\n",
    "Funkcja `df.groupby()` służy do grupowania danych w DataFrame'ie na podstawie wartości w określonej kolumnie lub kolumnach. W wyniku zastosowania funkcji `df.groupby()`, dane są dzielone na grupy, które następnie można analizować lub przetwarzać w różny sposób.\n",
    "\n",
    "Funkcja `df.groupby()` jest często wykorzystywana w analizie danych, w szczególności do agregacji danych, czyli łączenia ich w grupy i obliczania statystyk dla każdej grupy. Na przykład, jeśli mamy DataFrame z danymi sprzedażowymi, możemy zgrupować dane według kategorii produktów i obliczyć średnią, sumę lub inne statystyki sprzedaży dla każdej kategorii.\n",
    "\n",
    "Przykład wykorzystania funkcji `df.groupby()` w pandas:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Grupowanie danych według kolumny 'manufacturer_name' i 'model_name'.\n",
    "car_group = df.groupby(['manufacturer_name','model_name'])\n",
    "\n",
    "# Obliczanie sumy sprzedaży dla każdej grupy\n",
    "mean_price = car_group['price_usd'].mean()\n",
    "\n",
    "print(mean_price)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dane zostały podzielone na grupy ze względu na markę oraz model i obliczona została średnia cena sprzedaży dla każdej grupy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Istnieje możliwość pobrania grupy z ramki danych, która została wcześniej podzielona na grupy za pomocą metody `df.get_group()`. Metoda ta pobiera i zwraca grupę o określonym kluczu.\n",
    "\n",
    "Na przykład, jeśli interesuje nas grupa z marką `'Merceden-Benz'` i modelem `'Sprinter'` możemy wykonać to w następujący sposób."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "car_group.get_group(('Mercedes-Benz', 'Sprinter'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na grupie można wykorzystać wiele funkcji, między innymi:\n",
    "\n",
    "- Agregujące (np. sum, mean, count, min, max, median) - służą do łączenia wielu wartości w jedną wartość dla każdej grupy.\n",
    "- Transformujące (np. apply) - umożliwiają stosowanie dowolnej funkcji na każdej grupie i zwracają wynik tej samej długości, co grupa.\n",
    "- Filtrujące - pozwalają na wybór podzbioru danych na podstawie określonych warunków, np. zwracanie tylko grup, które spełniają określone kryteria.\n",
    "\n",
    "Istnieje wiele innych funkcji, które można stosować na grupie w zależności od potrzeb i rodzaju analizowanych danych."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na przykład jest to funkcja `df.agg()`. Funkcja ta umożliwia grupowanie wierszy DataFrame według wartości w określonej kolumnie lub kolumnach, a następnie wykonywanie na każdej grupie dowolnych operacji agregujących, takich jak np. sumowanie, obliczanie średniej, minimalnej i maksymalnej wartości itp.\n",
    "\n",
    "Funkcja `df.agg()` przyjmuje słownik, który mapuje nazwy kolumn na listę funkcji agregujących, które mają zostać wykonane dla tej kolumny. Na przykład, chcemy obliczyć trzy funkcje agregujące do każdej grupy:\n",
    "\n",
    "- liczbę wierszy w każdej grupie, co odpowiada liczbie wystąpień danego modelu danej marki.\n",
    "- sumę wartości w kolumnie `'duration_listed'` w każdej grupie, co odpowiada łącznemu czasowi trwania ogłoszeń dla danego modelu danej marki.\n",
    "- najmniejszą wartość w kolumnie `'year_produced'` w każdej grupie, co odpowiada najwcześniejszemu roku produkcji danego modelu danej marki."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "car_group = df.groupby(['manufacturer_name','model_name']).agg({'model_name': 'count', 'duration_listed': 'sum', 'year_produced': 'min'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "W efekcie uzyskujemy DataFrame zawierający informacje o liczbie wystąpień, czasie trwania ogłoszeń oraz najwcześniejszym roku produkcji dla każdego modelu danej marki.\n",
    "\n",
    "Jak już wspominaliśmy, iterowanie po wierszach lub kolumnach i stosowanie funkcji w pętli zwykle jest najmniej wydajnym rozwiązaniem przy operacjach na całym DataFrame, lub grupach wierszy. Dlatego funkcja `df.agg()` jest często stosowana w połączeniu z funkcjami agregującymi, takimi jak `sum`, `mean`, `max`, `min`, `count` i wiele innych, co pozwala na szybkie i łatwe obliczenie wielu statystyk dla danych.\n",
    "\n",
    "W przypadku bardziej złożonych operacji, które nie mogą być łatwo wykonane za pomocą funkcji agregujących, konieczne może być iterowanie po wierszach lub kolumnach. W takim przypadku warto jednak unikać pętli w Pythonie i stosować wektoryzację NumPy lub funkcje wbudowane w Pandas, takie jak `apply`, `map`, `transform`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standaryzacja i normalizacja"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Standaryzacja i normalizacja to techniki przetwarzania danych służące do skalowania wartości numerycznych w celu poprawy jakości analizy danych i modelowania. Standaryzacja odnosi się do przekształcenia danych numerycznych w sposób, który przesuwa średnią do zera i skaluje wartości wokół tej średniej przy użyciu odchylenia standardowego.\n",
    "\n",
    "Oto przykładowy kod wykonujący standaryzację kolumny `'duration_listed'`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_duration = df['duration_listed'].mean()\n",
    "std_duration = df['duration_listed'].std()\n",
    "df['duration_listed_standardized'] = (df['duration_listed'] - mean_duration) / std_duration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "W tym kodzie, do standaryzacji kolumny `'duration_listed'` używamy średniej (`mean`) i odchylenia standardowego (`std`) wyliczonych na podstawie tej kolumny. Następnie używamy tych wartości do przeskalowania wartości w kolumnie do wartości standardowych."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalizacja natomiast odnosi się do przekształcenia danych numerycznych w sposób, który przeskalowuje wartości w przedziale od 0 do 1 lub od -1 do 1, co pozwala na porównywanie i analizę danych z różnych skal.\n",
    "\n",
    "Oto przykładowy kod wykonujący normalizację kolumny `'year_produced'`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "min_year = df['year_produced'].min()\n",
    "max_year = df['year_produced'].max()\n",
    "df['year_produced_normalized'] = (df['year_produced'] - min_year) / (max_year - min_year)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do normalizacji kolumny `'year_produced'` używamy minimalnej (`min`) i maksymalnej (`max`) wartości z kolumny, aby przeskalować wartości do przedziału od 0 do 1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Standaryzacja i normalizacja są szczególnie przydatne w przypadku analizy danych numerycznych zawierających wiele zmiennych o różnych jednostkach i skalach. Wiele algorytmów uczenia maszynowego i statystycznych działa lepiej, gdy dane są w pewien sposób przetworzone, a normalizacja i standaryzacja to popularne techniki tego przetwarzania."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Zapisywanie do listy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Czasami potrzebujemy przekształcić obiekt DataFrame albo Series na listę.\n",
    "Służy do tego metoda df.tolist() i może być wywoływana na poszczególnych kolumnach lub wierszach w celu uzyskania ich wartości w postaci listy. Na przykład, wywołanie df['column_name'].tolist() zwróci listę wartości w danej kolumnie, a wywołanie df.iloc[row_index].tolist() zwróci listę wartości w danym wierszu.\n",
    "\n",
    "Jak ta funkcja może zostać użyta, prześledzimy na przykładzie szukania kolumn, które zawierają jakieś brakujące wartości.\n",
    "\n",
    "Funkcja df.isnull() zwraca tabelę boolean, w której wartości True odpowiadają brakującym wartościom (NaN) w DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df.isnull()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nie będziemy musieli przeszukiwać tabeli ręcznie, aby znaleźć wartości prawdziwe.\n",
    "\n",
    "Zamiast tego, możemy skorzystać z funkcji `df.value_counts()`, która zwraca serię zawierającą informacje o liczbie wystąpień unikalnych wartości w danej kolumnie. Wynik jest posortowany malejąco, co oznacza, że najczęściej występujące wartości będą znajdowały się na początku serii.\n",
    "\n",
    "Przykładowo, można użyć tej funkcji do zliczenia i wyświetlenia liczby i rodzaju wartości występujących w kolumnie `'transmission'`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['transmission'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interesują nas oddzielne statystyki dla każdej kolumny, dlatego policzymy, ile jest rekordów z wartością `True` i `False` dla każdej kolumny przy pomocy metody `df.apply()` i `df.value_counts()` na każdej kolumnie:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df.apply(lambda x: x.isnull().value_counts())"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Potem przy użyciu funkcji `df.loc` wybierzemy tylko wartości `True`, ponieważ interesują nas tylko brakujące dane:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bad = df.apply(lambda x: x.isnull().value_counts()).loc[True,:]\n",
    "df_bad"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mamy już informacje na temat ilości brakujących wartości w każdej kolumnie.\n",
    "\n",
    "Jednak interesują nas tylko kolumny, w których brakuje jakichś wartości (czyli te, w których liczba brakujących wartości jest większa od zera). Do wyboru tych kolumn ponownie wykorzystamy funkcję df.loc:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bad.loc[df_bad > 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na końcu chcemy uzyskać listę nazw kolumn, w których występują brakujące wartości.\n",
    "\n",
    "Wykorzystamy do tego atrybut `df.index`, który zwraca indeks wartości brakujących (zwróć uwagę, że nazwy kolumn z oryginalnego obiektu `df` są nazwami indeksów w nowym obiekcie `df_bad`), a funkcja `df.tolist()` przekonwertuje te wartości do listy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "list_of_missing = df_bad.loc[df_bad > 0].index.tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jeśli chcemy uzyskać indeksy wszystkich rekordów w obiekcie `df`, które zawierają przynajmniej jedną brakującą wartość, możemy wykorzystać następujący kod:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_of_missing_index = df.isnull().loc[df.isnull().any(axis=1), :].index.tolist()\n",
    "list_of_missing_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jedyną nową funkcją jest tutaj`df.any()`. Funkcja ta zwraca wartość boolowską (`True` lub `False`) dla każdej kolumny. W przypadku kolumny, jeśli przynajmniej jedna wartość w kolumnie jest `True`, to cała kolumna jest uznawana za `True`, a w przeciwnym przypadku za `False`. Dzięki temu można sprawdzić, czy w kolumnie znajdują się jakieś wartości `True`, co może być przydatne w analizie danych lub filtrowaniu DataFrame'a."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Uzupełnianie danych"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Brakujące dane mogą przeszkadzać w analizie danych, ponieważ mogą prowadzić do niepełnych lub błędnych wyników. Brakujące dane mogą wprowadzić szumy do analizy danych, zaburzając wyniki statystyczne lub modele predykcyjne. Dlatego ważne jest, aby umiejętnie radzić sobie z brakującymi danymi, np. poprzez uzupełnianie ich lub usuwanie w zależności od kontekstu i charakteru danych."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oto kilka możliwych sposobów postępowania z brakującymi wartościami:\n",
    "\n",
    "- Usunięcie rekordów z brakującymi wartościami - w przypadku małej liczby brakujących wartości, które nie wpływają znacząco na analizę danych, możemy usunąć rekordy zawierające te braki. Jednak w przypadku większej liczby braków może to prowadzić do znacznego zmniejszenia liczby rekordów i utraty ważnych informacji.\n",
    "\n",
    "- Zastąpienie brakujących wartości średnią lub medianą - jeśli brakuje niewielka liczba wartości, które można uzupełnić, można użyć średniej lub mediany z pozostałych wartości w kolumnie. Ten sposób może być dobrym wyborem, gdy nie zależy nam na precyzyjnym odwzorowaniu brakującej wartości.\n",
    "\n",
    "- Zastąpienie brakujących wartości wartością domyślną - w przypadku niektórych zmiennych, takich jak płci lub stan cywilny, brakującą wartość można zastąpić wartością domyślną, taką jak \"nieznany\" lub \"brak danych\".\n",
    "\n",
    "- Uzupełnienie brakujących wartości na podstawie innych zmiennych - można użyć innych zmiennych, które mają wartości, aby uzupełnić brakujące wartości. Na przykład, jeśli brakuje daty urodzenia, można użyć wieku i daty bieżącej, aby określić datę urodzenia.\n",
    "\n",
    "- Użycie modeli predykcyjnych do uzupełnienia brakujących wartości - można użyć modeli predykcyjnych, takich jak regresja liniowa lub maszyny wektorów nośnych, aby przewidzieć brakujące wartości na podstawie innych zmiennych.\n",
    "\n",
    "Ostatecznie wybór sposobu postępowania z brakującymi wartościami zależy od kontekstu danych i celów analizy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Załóżmy, że w kolumnie `'odometer_value'` i `'transmission'` występują brakujące wartości. Aby ich nie usuwać, postanawiamy je zastąpić wartościami reprezentatywnymi dla danej kolumny.\n",
    "\n",
    "W przypadku `'odometer_value'` wykorzystamy średnią wartość z całej kolumny, którą można obliczyć przy użyciu metody `df.mean()`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_odometer_value = df['odometer_value'].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of odometer :\", avg_odometer_value)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aby zastąpić brakujące wartości, użyjemy metody `df.replace()` i podamy jej jako argument słownik, który określa wartości, jakie mają zostać zastąpione dla danego klucza."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"odometer_value\"] = df[\"odometer_value\"].replace(np.nan, avg_odometer_value)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dla kolumny `'transmission'`  zastosujemy wartość modalną, czyli wartość, która pojawia się najczęściej w danych. Są to dane opisowe, więc nie możemy policzyć dla nich ani średniej, ani mediany."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_transmission_value = df['transmission'].mode().item()\n",
    "#max_transmission_value = df['transmission'].value_counts().idxmax() #alternatywnie\n",
    "print(\"Max value of transmission:\", max_transmission_value)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Następnie, tak samo, jak dla `'odometer_value'`, zastąpimy brakujące wartości metodą `df.replace()`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['transmission'] = df['transmission'].replace(np.nan, max_transmission_value)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jeśli istnieją brakujące wartości, których nie da się uzupełnić, na przykład brakuje ceny samochodu, musimy je usunąć.\n",
    "\n",
    "Możemy to zrobić za pomocą metody `df.dropna()`, która usuwa wiersze lub kolumny, w zależności od ustawionego argumentu axis.\n",
    "\n",
    "Aby usunąć tylko wiersze z brakującymi wartościami, możemy ustawić `axis=0`.\n",
    "\n",
    "Po usunięciu brakujących wartości można zresetować indeksy za pomocą metody `df.reset_index()`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['price_usd'], axis=0)\n",
    "df = df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
